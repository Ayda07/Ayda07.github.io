<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>Sources</title>
        <link rel="stylesheet" href="style.css">
    </head>
    <body style="background-image: url('Images/Machine_Learning.gif')">
        <div class="navbar">
            <div id="head" style="text-align: center">
                <h1 style="text-align: center">Bias and Discrimination From Algorithms</h1>
            </div>
            <a href="index.html">Home</a>
            <a href="criminal_justice.html">Criminal Justice</a>
            <a href="social.html">Society</a>
            <a href="sources.html">Sources</a>
        </div>
        <div class="main" style="display: block">
            <div class="textbox center-float">
                <h2>
                    Public Influence
                </h2>
                <div class="section">
                    <p>
                        The introduction of recommendation algorithms caused use of the internet to surge, especially in
                        respect to social spheres. Although they are very convenient and fun, recommendation algorithms
                        can have serious impacts on huge sections of society. These algorithms use engagement data to
                        create "a narrowly construed set that comes from successfully fitting other people, past
                        actions, and inanimate objects into categories using categories to discipline action,"
                        (Ananny, 103). The use of engagement as a target for these algorithms drive forward increasingly
                        controversial, violent media, pushing users towards the groups at either side of the social spectrum.
                        Additionally, this algorithmic clustering enforces group stereotypes and a form of mob mentality
                        formed by echo chambers of ideas online.
                    </p>
                </div>
            </div>
            <div class="textbox center-float">
                <h2>
                    Opportunity Screening
                </h2>
                <div class="section">
                    <div style="float: right; margin-left: 20px; margin-bottom: 20px">
                        <img src="Images/RaceBlindGraph.png" title="(Kleinberg, 159)" alt="Figure 2 (Kleiberg, 159)"/>

                    </div>
                    <p>
                        Machine learning algorithms are often used in systems that screen applicants to jobs, schools,
                        and programs. Due to the types of data used to rank these applicants race or other social
                        groupings are often included implicitly. As shown in the chart to the right algorithms designed
                        to be race blind, will actually negatively effect those they try to benefit, in this case black
                        students. This error is caused "because the relationships between [the data,] high school
                        predictors and [the outcome,] college success turn out differently for [different groups,] white
                        and black students," (Kleinberg, 159). Carefully considering what data is provided to a system is
                        extremely necessary to avoiding a biased algorithm as even seemingly innocuous data can reflect
                        discriminatory social trends.
                    </p>
                    <p>
                        To prevent the propagation of discriminatory practices we must ensure "human scrutiny of the
                        results of algorithms used to make life-changing decisions," (Gumbus, 123).
                        Unfortunately machine learning algorithms inherently conceal how the
                        provided data is used. This black box effect makes it much more difficult to detect weather or
                        not a decision was based on biased observations. You can't know whether you were denied
                        certain opportunities such as a job or scholarship due to something outside your control.
                        Without carefully and openly analysing the implications of the data given to the system we cannot
                        recognize the discrimination perpetuated by flawed systems.
                    </p>
                </div>
            </div>
        </div>
    </body>
</html>